---
title: "IML_project"
author: "Heikki Nenonen"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

## Todo

-   ~~dummy classifier~~

-   ~~class4 -\> event/nonevent, week1 exe?~~

-   ~~drop partlybad, pelkkää FALSEa~~

-   **varianssit mukana/ei mukana? ei one hot -\> yksinkertaistaa liikaa ja tarkoitettu kategoriseen dataan**

-   ~~date? paljon informaatiota, mutta halutaanko muuttujaksi \<- opeta 2000-2008, testaa 2009-2011 / kysy slack test_hidden ei - - date, jätetäänkö pois? good riddance!~~

-   ~~train, test, cv-10?~~

-   ~~itse logisticregression, week2 exe1 \<- lasso/ridge~~

-   ~~accuracy, perplexity, week2 exe1~~

-   accuracy of our accuracy? \<-- malli train+test, vähän parempi kuin pelkkä train?

-   ~~class4 -\> nonevent/1a/1b/II/ = 0,1,2,3~~

-   googlaa mahdollisia malleja

-   logreg/randomforest/qda with default parameters are best atm, maybe we can optimize

-   plot

    ```{r include=FALSE}
    library(reticulate)
    ```

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model

#npf_test = pd.read_csv("initial_data/npf_test_hidden.csv")
npf_train = pd.read_csv("initial_data/npf_train.csv")


```

```{python echo=TRUE}

npf_train_test = npf_train.set_index("date")
npf_train_test = npf_train_test.drop(['id', 'partlybad'], axis=1)

class2 = np.array(["nonevent", "event"])
class2 = class2[(npf_train_test["class4"]!="nonevent").astype(int)]
#class2 = class2.apply(lambda x: 1 if "event" else 0)
npf_train_test.insert(loc=0, column="class2", value=class2)

npf_train_test["class2"].replace(["event", "nonevent"],[1,0], inplace=True)
npf_train_test["class4"].replace(["nonevent", "Ia", "Ib", "II"],[0, 1, 2, 3], inplace=True)


```

First five columns and rows

```{r}
knitr::kable(head(py$npf_train_test[,1:5]), row.names = TRUE, digits = 2)
```

```{python include=FALSE}
from sklearn.dummy import DummyClassifier
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LogisticRegression 
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, accuracy_score

from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

from sklearn.neighbors import KNeighborsClassifier

#from sklearn.utils.testing import ignore_warnings
from sklearn.exceptions import ConvergenceWarning
```

```{python}
#@ignore_warnings(category=ConvergenceWarning)
def loss(X_tr, y_tr, X_te, y_te, m):
    return mean_squared_error(y_te, m.fit(X_tr, y_tr).predict(X_te), squared=False)


def accuracy(X_tr, y_tr, X_te, y_te, m):
    return accuracy_score(y_te, m.fit(X_tr, y_tr).predict(X_te))

#def perplexity(p, y_test):
#    return np.exp(-np.mean(np.log(y_test*p + (1 - y_test) * (1 - p))))

#perplexity = lambda p: np.exp(-np.mean(np.log(y_test*p + (1 - y_test) * (1 - p))))

```

```{python include=FALSE}
def magic(models, classtype):
  X = npf_train_test.drop(["class2", "class4"], axis=1, inplace=False)
  y = npf_train_test[classtype]
  X_train, X_test, y_train, y_test = train_test_split(
      X, y, train_size=0.9, random_state=40, shuffle=True, stratify=y
  )
  
  res = pd.DataFrame(index=models)
  # Loss on training data, for model trained on training data:
  res["train_loss"] = [loss(X_train, y_train, X_train, y_train, m) for m in models]
  # Cross-validation loss:
  res["cv_loss"] = [
      -cross_val_score(
          m, X_train, y_train, cv=10, scoring="neg_root_mean_squared_error"
      ).mean()
      for m in models
  ]
  # Los on test data, for model trained on training data:
  res["test_loss"] = [loss(X_train, y_train, X_test, y_test, m) for m in models]
  res["test_accuracy"] = [accuracy(X_train, y_train, X_test, y_test, m) for m in models]
  
  perplexity = lambda p: np.exp(-np.mean(np.log(y_test*p + (1 - y_test) * (1 - p))))
  
  #temporary solution since svm is weird with perplexity, KEEP SVM LAST!!
  list = [perplexity(m.predict_proba(X_test)[:,1]) for m in models[0:-1]]
  res["test_perplexity1"]= np.append(list, 0)
  
  return res

```

```{python include=FALSE}

models = [DummyClassifier(), 
  LogisticRegression(penalty="l2", C=1_000, solver="lbfgs"), 
  LogisticRegression(penalty="elasticnet", l1_ratio=0.5, solver="saga"), 
  LogisticRegression(penalty="l2", C=1, solver="saga"), 
  LogisticRegression(penalty="none", solver="lbfgs"), 
  LogisticRegression(penalty="l1", C=1, solver="saga"),
  GaussianNB(),
  QuadraticDiscriminantAnalysis(),
  RandomForestClassifier(),
  KNeighborsClassifier(),
  make_pipeline(StandardScaler(), SVC(gamma='auto'))
  ]
  #make_pipeline(StandardScaler(), SVC(gamma='auto'))
 #  DummyRegressor(),
  
  
results_class2 = magic(models, 'class2')
results_class4 = magic(models, 'class4')
```

```{python}
test = results_class2.reset_index()
```

```{r}
knitr::kable(py$results_class2, row.names = TRUE, digits = 2)
knitr::kable(py$results_class4, row.names = TRUE, digits = 2)
#as.matrix(py$test)
#knitr::kable(py$test, digits = 2)

```

```{python}
#shows all columns 
#required package tabulate 
#print(res.to_markdown())
models = [  
  RandomForestClassifier(criterion='gini'),
  RandomForestClassifier(criterion='log_loss'),
  RandomForestClassifier(criterion='entropy')]
  
results_class4 = magic(models, 'class4')


```

```{python}

print(results_class4.to_markdown())

```
