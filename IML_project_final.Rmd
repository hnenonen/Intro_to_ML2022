---
title: "IML_project"
author: "Heikki Nenonen"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

## Todo

-   ~~dummy classifier~~

-   ~~class4 -\> event/nonevent, week1 exe?~~

-   ~~drop partlybad, pelkkää FALSEa~~

-   **varianssit mukana/ei mukana? ei one hot -\> yksinkertaistaa liikaa ja tarkoitettu kategoriseen dataan**

-   ~~date? paljon informaatiota, mutta halutaanko muuttujaksi \<- opeta 2000-2008, testaa 2009-2011 / kysy slack test_hidden ei - - date, jätetäänkö pois? good riddance!~~

-   ~~train, test, cv-10?~~

-   ~~itse logisticregression, week2 exe1 \<- lasso/ridge~~

-   ~~accuracy, perplexity, week2 exe1~~

-   accuracy of our accuracy? \<-- malli train+test, vähän parempi kuin pelkkä train?

-   ~~class4 -\> nonevent/1a/1b/II/ = 0,1,2,3~~

-   try normalising data - google if needed for RF

-   try PCA

-   googlaa mahdollisia malleja

-   logreg/randomforest/qda with default parameters are best atm, maybe we can optimize

-   plot

    ```{r include=FALSE}
    library(reticulate)
    ```

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model

npf_test = pd.read_csv("initial_data/npf_test_hidden.csv")
npf_train = pd.read_csv("initial_data/npf_train.csv")


```

```{python echo=TRUE}

npf_train_test = npf_train.set_index("date")
npf_train_test = npf_train_test.drop(['id', 'partlybad'], axis=1)

class2 = np.array(["nonevent", "event"])
class2 = class2[(npf_train_test["class4"]!="nonevent").astype(int)]
#class2 = class2.apply(lambda x: 1 if "event" else 0)
npf_train_test.insert(loc=0, column="class2", value=class2)

npf_train_test["class2"].replace(["event", "nonevent"],[1,0], inplace=True)
npf_train_test["class4"].replace(["nonevent", "Ia", "Ib", "II"],[0, 1, 2, 3], inplace=True)

#DROPS STDS
npf_train_test = npf_train_test.filter(regex='mean|class4|class2')


```

First five columns and rows

```{r}
knitr::kable(head(py$npf_train_test[,1:5]), row.names = TRUE, digits = 2)
```

```{python include=FALSE}
from sklearn.dummy import DummyClassifier
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LogisticRegression 
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, accuracy_score

from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

from sklearn.neighbors import KNeighborsClassifier

from sklearn.decomposition import PCA

#from sklearn.utils.testing import ignore_warnings
from sklearn.exceptions import ConvergenceWarning
```

```{python}
#@ignore_warnings(category=ConvergenceWarning)
def loss(X_tr, y_tr, X_te, y_te, m):
    return mean_squared_error(y_te, m.fit(X_tr, y_tr).predict(X_te), squared=False)


def accuracy(X_tr, y_tr, X_te, y_te, m):
    return accuracy_score(y_te, m.fit(X_tr, y_tr).predict(X_te))

#def perplexity(p, y_test):
#    return np.exp(-np.mean(np.log(y_test*p + (1 - y_test) * (1 - p))))

#perplexity = lambda p: np.exp(-np.mean(np.log(y_test*p + (1 - y_test) * (1 - p))))

```

```{python}


def magic(models, classtype):
  
  X = npf_train_test.drop(["class2", "class4"], axis=1, inplace=False)
  y = npf_train_test[classtype]
  X_train, X_test, y_train, y_test = train_test_split(
      X, y, train_size=0.8, random_state=40, shuffle=True, stratify=y
  )
  
  
  res = pd.DataFrame(index=models)
  # Loss on training data, for model trained on training data:
  res["train_loss"] = [loss(X_train, y_train, X_train, y_train, m) for m in models]
  # Cross-validation loss:
  res["cv_loss"] = [
      -cross_val_score(
          m, X_train, y_train, cv=10, scoring="neg_root_mean_squared_error"
      ).mean()
      for m in models
  ]
  # Los on test data, for model trained on training data:
  res["test_loss"] = [loss(X_train, y_train, X_test, y_test, m) for m in models]
  res["test_accuracy"] = [accuracy(X_train, y_train, X_test, y_test, m) for m in models]
  
  perplexity = lambda p: np.exp(-np.mean(np.log(y_test*p + (1 - y_test) * (1 - p))))
  
  #temporary solution since svm is weird with perplexity, KEEP SVM LAST!!
  list = [perplexity(m.predict_proba(X_test)[:,1]) for m in models[0:-1]]
  res["test_perplexity1"]= np.append(list, 0)
  
  return res

```

```{python include=FALSE}

models = [DummyClassifier(), 
  LogisticRegression(penalty="l2", C=1_000, solver="lbfgs"), 
  LogisticRegression(penalty="elasticnet", l1_ratio=0.5, solver="saga"), 
  LogisticRegression(penalty="l2", C=1, solver="saga"), 
  LogisticRegression(penalty="none", solver="lbfgs"), 
  LogisticRegression(penalty="l1", C=1, solver="saga"),
  GaussianNB(),
  QuadraticDiscriminantAnalysis(),
  RandomForestClassifier(),
  KNeighborsClassifier(),
  make_pipeline(StandardScaler(), SVC(gamma='auto'))
  ]
  #make_pipeline(StandardScaler(), SVC(gamma='auto'))
 #  DummyRegressor(),
  
  
results_class2 = magic(models, 'class2')
results_class4 = magic(models, 'class4')
```

```{python}
test = results_class2.reset_index()
```

```{r}
knitr::kable(py$results_class2, row.names = TRUE, digits = 2)
knitr::kable(py$results_class4, row.names = TRUE, digits = 2)
#as.matrix(py$test)
#knitr::kable(py$test, digits = 2)

```

```{python}
#shows all columns 
#required package tabulate 
#print(res.to_markdown())
models = [  
  RandomForestClassifier(criterion='gini'),
  RandomForestClassifier(criterion='log_loss'),
  RandomForestClassifier(criterion='entropy')]
  
results_class4 = magic(models, 'class4')


```

```{r}
knitr::kable(py$results_class4, row.names = TRUE, digits = 2)

```

```{python}
npf_test_clean = npf_test.drop(['id', 'partlybad', 'date'], axis=1)

#DROPS STDS
npf_test_clean = npf_test_clean.filter(regex='mean|class4|class2')


##
#
##

X = npf_train_test.drop(columns=['class2', 'class4'])
y = npf_train_test['class2']
rfc = RandomForestClassifier(criterion='gini')
model = rfc.fit(X, y)

predict_x = npf_test_clean.drop(columns='class4')

probas = pd.DataFrame(predict_x.copy())


def get_predict_proba(row, model):
  probas = model.predict_proba(row.values.reshape(1,-1))
  
  nonevent_p = probas[0][0]
  event_p = 1-nonevent_p
  #print(np.sum(probas[0][1:]))
  #print(f'nonev: {nonevent_p}, event_sum: {event_p}, all: {probas}')
   
  #ret = max(nonevent_p, event_p)
  return event_p 

probas['proba'] = probas.apply(lambda row: get_predict_proba(row, model), axis=1)

predicts = pd.DataFrame(model.predict(predict_x))

final = predicts.merge(probas['proba'].to_frame(), left_index=True, right_index=True)

final[0].replace([0, 1],["nonevent", "event"], inplace=True)
```

```{python}

npf_test_clean = npf_test.drop(['id', 'partlybad', 'date'], axis=1)

#DROPS STDS
npf_test_clean = npf_test_clean.filter(regex='mean|class4|class2')

npf_train_events = npf_train_test[npf_train_test['class2']==1]
X = npf_train_events.drop(columns=['class2', 'class4'])
y = npf_train_events['class4']
rfc = RandomForestClassifier(criterion='gini')
model = rfc.fit(X, y)


predict_x = npf_test_clean.loc[final[final[0]=='event'].index].drop(columns='class4')

#final[final[0]=='event'].index

#probas['proba'] = probas.apply(lambda row: get_predict_proba(row, model), axis=1)

predicts = pd.DataFrame(model.predict(predict_x))


predicts[0].replace([1, 2, 3],["Ia", "Ib", "II"], inplace=True)

i = 0
for index, row in final.iterrows():
  if row[0]=='event':
    #print(f'i: {i}, predict: {predicts.iloc[i,0]}')
    #row[0] = predicts.iloc[i,0]
    final.at[index, 0] = predicts.iloc[i,0]
    i += 1
  
#final = predicts.merge(probas['proba'].to_frame(), left_index=True, right_index=True)
#final[0].replace([0, 1, 2, 3],["nonevent", "Ia", "Ib", "II"], inplace=True)

```

```{python}
row0 = pd.DataFrame({0: 0.9, 'proba':''}, index =[0])
row1 = pd.DataFrame({0: 'class4', 'proba':'p'}, index =[0])
merged = pd.concat([row1, final])
merged = pd.concat([row0, merged])

merged.to_csv('answers.csv', index=False, header=False)
```
